{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare reference data\n",
    "\n",
    "## Installation\n",
    "\n",
    "- Edit `.git/configure` to set up `upstream` remote:\n",
    "\n",
    "```\n",
    "[remote \"upstream\"]\n",
    "\turl = <URL of GitHub repository or Azure mirror>\n",
    "\tfetch = +refs/heads/*:refs/remotes/upstream/*\n",
    "    fetch = +refs/pull/*/head:refs/remotes/upstream/pr/*\n",
    "```\n",
    "\n",
    "- Initialize LFS hooks and fetch references from `upstream`:\n",
    "```\n",
    "$ git lfs install\n",
    "$ git fetch upstream\n",
    "```\n",
    "\n",
    "Activate the tardis environment:\n",
    "```\n",
    "$ conda activate tardis\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "- Run this notebook **inside** the `tardis-refdata/notebooks` directory.\n",
    "\n",
    "\n",
    "- *ReferenceComparer* object loads two versions of the reference data by passing **at least** one Git label (e.g. *hash, tag, branch name*). If either is set to `None` it will just use the current data in the directory. For example:\n",
    "```python\n",
    "comparer = ReferenceComparer(ref1_hash=None, ref2_hash='upstream/master')\n",
    "```\n",
    "  compares `unit_test_data.h5` from your local repository against the `HEAD` of the `upstream` remote.\n",
    "  \n",
    "  Please set the labels you want to compare now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF1_HASH_DEFAULT = None\n",
    "REF2_HASH_DEFAULT = 'upstream/master'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **This feature is specially useful for CI pipelines:** `ref1_hash` and `ref2_hash` parameters can be passed as environment variables before running the notebook, overwriting the defaults defined in the above cell. \n",
    "  ```\n",
    "  export REF2_HASH='upstream/master'\n",
    "  ```\n",
    "\n",
    "- If you want to switch to the `matplotlib` backend pass the `mpl_backend=True` option to the `compare_output_nu` and `compare_spectrum` function.\n",
    "\n",
    "\n",
    "- Use `.teardown()` method to delete temporary files.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:09:13.639421Z",
     "start_time": "2018-08-02T12:09:13.633620Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "output_notebook()\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you are in the root of `tardis-refdata` after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pickled with protocol 5 can't be opened with `python<3.8.3`, use the backport\n",
    "\n",
    "if sys.version_info < (3, 8, 3):\n",
    "    import pickle5\n",
    "\n",
    "    sys.modules[\"pickle\"] = pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T09:58:38.546226Z",
     "start_time": "2018-08-02T09:58:38.541396Z"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_missing(val):\n",
    "    if val == True:\n",
    "        return 'background-color: #BCF5A9'\n",
    "    else:\n",
    "        return 'background-color: #F5A9A9'\n",
    "    \n",
    "def highlight_relative_difference(val):\n",
    "    ret = 'background-color: #BCF5A9'\n",
    "    if val is None:\n",
    "        ret = 'background-color: #BCF5A9'\n",
    "    elif val > 1e-2:\n",
    "        ret = 'background-color: #F2F5A9'\n",
    "    elif val > 1e-1:\n",
    "        ret = 'background-color: #F5D0A9'\n",
    "    elif val > 1:\n",
    "        ret = 'background-color: #F5A9A9'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:29:57.536422Z",
     "start_time": "2018-08-02T12:29:57.448981Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReferenceComparer(object):\n",
    "\n",
    "    def __init__(self, ref1_hash=None, ref2_hash=None, compare_path='unit_test_data.h5'):\n",
    "        assert not ((ref1_hash is None) and (ref2_hash is None)), \"One hash can not be None\"\n",
    "        self.ref1_hash = ref1_hash\n",
    "        self.ref2_hash = ref2_hash\n",
    "        self.compare_path = compare_path\n",
    "        self.tmp_dir = None\n",
    "        self.setup()\n",
    "    \n",
    "    def setup(self):\n",
    "        self.tmp_dir = tempfile.mkdtemp()\n",
    "        print('Created temporary directory at {0}. Delete after use with .teardown'.format(self.tmp_dir))\n",
    "        for ref_id, ref_hash in enumerate([self.ref1_hash, self.ref2_hash]):\n",
    "            ref_id += 1\n",
    "            if ref_hash is not None:\n",
    "                self._copy_data_from_hash(ref_hash, 'ref{0}_'.format(ref_id))\n",
    "            else:\n",
    "                subprocess.Popen('cp {0} {1}'.format(self.compare_path, \n",
    "                                                     os.path.join(self.tmp_dir, \n",
    "                                                                  'ref{0}_{1}'.format(ref_id, self.compare_path))), \n",
    "                                                     shell=True)\n",
    "            setattr(self, 'ref{0}_fname'.format(ref_id), \n",
    "                    os.path.join(self.tmp_dir, 'ref{0}_{1}'.format(ref_id, self.compare_path)))\n",
    "\n",
    "    def teardown(self):\n",
    "        shutil.rmtree(self.tmp_dir)\n",
    "\n",
    "    def _copy_data_from_hash(self, ref_hash, prefix):\n",
    "        git_cmd = ['git']\n",
    "        git_cmd.append('--work-tree={0}'.format(self.tmp_dir))\n",
    "        git_cmd += ['checkout', ref_hash, self.compare_path]\n",
    "        p = subprocess.Popen(git_cmd)\n",
    "        p.wait()\n",
    "        shutil.move(os.path.join(self.tmp_dir, self.compare_path), \n",
    "                    os.path.join(self.tmp_dir, prefix + self.compare_path))\n",
    "\n",
    "    def generate_test_table(self):\n",
    "        rd1_hdfs = pd.HDFStore(self.ref1_fname, mode='r')\n",
    "        rd2_hdfs = pd.HDFStore(self.ref2_fname, mode='r')\n",
    "        rd1_keys = rd1_hdfs.keys()\n",
    "        rd2_keys = rd2_hdfs.keys()\n",
    "        rd1_hdfs.close()\n",
    "        rd2_hdfs.close()\n",
    "        rd1_df = pd.DataFrame(index=rd1_keys, columns=['exists'])\n",
    "        rd2_df = pd.DataFrame(index=rd2_keys, columns=['exists'])\n",
    "        rd1_df['exists'] = True\n",
    "        rd2_df['exists'] = True\n",
    "        joined_df = rd1_df.join(rd2_df, how='outer', lsuffix='_1', rsuffix='_2')\n",
    "        joined_df = joined_df.fillna(False)\n",
    "        return joined_df\n",
    "    \n",
    "    def compare_refdata(self, test_table):\n",
    "        test_table['match'] = None\n",
    "        test_table['abs_diff_mean'] = None\n",
    "        test_table['abs_diff_max'] = None\n",
    "        test_table['rel_diff_mean'] = None\n",
    "        test_table['rel_diff_max'] = None\n",
    "        for row_id, row in test_table.iterrows():\n",
    "            \n",
    "            if row[['exists_1', 'exists_2']].all():\n",
    "                ref1_df = pd.read_hdf(self.ref1_fname, row_id)\n",
    "                ref2_df = pd.read_hdf(self.ref2_fname, row_id)\n",
    "                \n",
    "                if isinstance(ref1_df, pd.Series):\n",
    "                    try:\n",
    "                        pd.testing.assert_series_equal(ref1_df, ref2_df)\n",
    "                    except AssertionError:\n",
    "                        test_table.loc[row_id, 'match'] = False\n",
    "                        abs_diff = np.fabs(ref1_df - ref2_df)\n",
    "                        rel_diff = (abs_diff / np.fabs(ref1_df))[ref1_df != 0]\n",
    "                        test_table.loc[row_id, 'abs_diff_mean'] = abs_diff.mean()\n",
    "                        test_table.loc[row_id, 'abs_diff_max'] = abs_diff.max()\n",
    "                        test_table.loc[row_id, 'rel_diff_mean'] = rel_diff.mean()\n",
    "                        test_table.loc[row_id, 'rel_diff_max'] = rel_diff.max()\n",
    "                    else:\n",
    "                        test_table.loc[row_id, 'match'] = True\n",
    "\n",
    "                elif isinstance(ref1_df, pd.DataFrame):\n",
    "                    try:\n",
    "                        pd.testing.assert_frame_equal(ref1_df, ref2_df)\n",
    "                    except AssertionError:\n",
    "                        test_table.loc[row_id, 'match'] = False\n",
    "                        abs_diff = np.fabs(ref1_df - ref2_df)\n",
    "                        rel_diff = (abs_diff / np.fabs(ref1_df))[ref1_df != 0]\n",
    "                        test_table.loc[row_id, 'abs_diff_mean'] = abs_diff.mean(skipna=True).mean()\n",
    "                        test_table.loc[row_id, 'abs_diff_max'] = abs_diff.max(skipna=True).max()\n",
    "                        test_table.loc[row_id, 'rel_diff_mean'] = rel_diff.mean(skipna=True).mean()\n",
    "                        test_table.loc[row_id, 'rel_diff_max'] = rel_diff.max(skipna=True).max()\n",
    "                    else:\n",
    "                        test_table.loc[row_id, 'match'] = True\n",
    "\n",
    "                else:\n",
    "                    raise ValueError('Needs to be a Series or DataFrame but is' + str(type(ref1_df)))\n",
    "        return test_table\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Check if `REF1_HASH` and `REF2_HASH` are environment variables. If not defined (or empty), use the defaults defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    REF1_HASH = os.environ['REF1_HASH']\n",
    "\n",
    "    if not REF1_HASH:\n",
    "        raise ValueError\n",
    "\n",
    "except (KeyError, ValueError):\n",
    "    REF1_HASH = REF1_HASH_DEFAULT\n",
    "\n",
    "try:\n",
    "    REF2_HASH = os.environ['REF2_HASH']\n",
    "\n",
    "    if not REF2_HASH:\n",
    "        raise ValueError\n",
    "\n",
    "except (KeyError, ValueError):\n",
    "    REF2_HASH = REF2_HASH_DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF1_HASH, REF2_HASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:30:01.760461Z",
     "start_time": "2018-08-02T12:30:01.343245Z"
    }
   },
   "outputs": [],
   "source": [
    "comparer = ReferenceComparer(ref1_hash=REF1_HASH, ref2_hash=REF2_HASH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:30:19.494810Z",
     "start_time": "2018-08-02T12:30:18.252462Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = comparer.generate_test_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:31:18.320558Z",
     "start_time": "2018-08-02T12:31:12.941859Z"
    }
   },
   "outputs": [],
   "source": [
    "tt = comparer.compare_refdata(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:31:22.806199Z",
     "start_time": "2018-08-02T12:31:22.707055Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt[[\"exists_1\", \"exists_2\", 'rel_diff_mean', 'rel_diff_max', 'match']].style.applymap(\n",
    "    highlight_missing, subset=['exists_1', 'exists_2', 'match']).applymap(\n",
    "    highlight_relative_difference, subset=['rel_diff_mean', 'rel_diff_max'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed inspection of the reference data\n",
    "\n",
    "If parts of the reference data show differences between revisions, you should invest some time examining these differences in detail. Often, visualizing the relevant data blocks already helps. \n",
    "\n",
    "You can use the following plotting routines as a blueprint and adjust and extend them to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_output_nu(df1, df2, mpl_backend=False):\n",
    "    nu_min = np.min([df1.min(), df2.min()])\n",
    "    nu_max = np.max([df1.max(), df2.max()])\n",
    "    \n",
    "    fig = make_subplots(rows=1, cols=2)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=df1, y=df2, mode=\"markers\", marker=dict(size=3)), row=1, col=1\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"output_nu, ref 1\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"output_nu, ref 2\", row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df1,\n",
    "            nbinsx=100,\n",
    "            histfunc=\"count\",\n",
    "            name=\"ref 1\",\n",
    "            marker=dict(color='rgba(0,0,0,0)', line=dict(width=1, color='orange')),\n",
    "            opacity=0.5,\n",
    "            xbins=dict(start=nu_min, end=nu_max, size=(nu_max - nu_min) / 100),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df2,\n",
    "            nbinsx=100,\n",
    "            histfunc=\"count\",\n",
    "            name=\"ref 2\",\n",
    "            marker=dict(color='rgba(0,0,0,0)', line=dict(width=1, color='blue')),\n",
    "            xbins=dict(start=nu_min, end=nu_max, size=(nu_max - nu_min) / 100),\n",
    "            opacity=0.5,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.update_layout(barmode=\"overlay\", height=550)  # Overlay the histograms\n",
    "    fig.update_xaxes(title_text=\"output_nu\", row=1, col=2)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spectrum(ref1_nu, ref1_lam, ref1_L, ref2_nu, ref2_lam, ref2_L, mpl_backend=False):\n",
    "    fig = make_subplots(rows=2, cols=2,)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ref1_nu, y=ref1_L, mode='lines', name='ref 1', marker=dict(size=2)), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=ref2_nu, y=ref2_L, mode='lines', name='ref 2', marker=dict(size=2)), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ref1_nu, y=ref1_L / ref2_L, mode='markers', name='L ref 1 / L ref 2', marker=dict(size=2)), row=1, col=2)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ref1_lam, y=ref1_L, mode='lines', name='ref 1', marker=dict(size=2)), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=ref2_lam, y=ref2_L, mode='lines', name='ref 2', marker=dict(size=2)), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=ref1_lam, y=ref1_L / ref2_L, mode='markers', name='L ref 1 / L ref 2', marker=dict(size=2)), row=2, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"nu\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"L\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"nu\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"L ref 1 / L ref 2\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"lambda\", row=2, col=1, tickformat='.2e')\n",
    "    fig.update_yaxes(title_text=\"L\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"lambda\", row=2, col=2, tickformat='.2e')\n",
    "    fig.update_yaxes(title_text=\"L ref 1 / L ref 2\", row=2, col=2)\n",
    "    fig.update_layout(height=1000)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data and find all the entries for which differences exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = pd.HDFStore(comparer.ref1_fname, \"r\")\n",
    "tmp2 = pd.HDFStore(comparer.ref2_fname, \"r\")\n",
    "\n",
    "diff_entries = tt.loc[(tt[\"match\"] == False) & (tt[\"exists_1\"] == True) & (tt[\"exists_2\"] == True)].index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_output_nu(tmp1['/test_simulation/output_nu'], tmp2['/test_simulation/output_nu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spectrum(tmp1['/test_transport_simple/spectrum/_frequency'][:-1], \n",
    "                 tmp1['/test_transport_simple/spectrum/wavelength'],\n",
    "                 tmp1['/test_transport_simple/spectrum/luminosity'],\n",
    "                 tmp2['/test_transport_simple/spectrum/_frequency'][:-1], \n",
    "                 tmp2['/test_transport_simple/spectrum/wavelength'],\n",
    "                 tmp2['/test_transport_simple/spectrum/luminosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spectrum(tmp1['/test_transport_simple_integral_macroatom_interp/spectrum/_frequency'][:-1], \n",
    "                 tmp1['/test_transport_simple_integral_macroatom_interp/spectrum/wavelength'],\n",
    "                 tmp1['/test_transport_simple_integral_macroatom_interp/spectrum_integrated/luminosity'],\n",
    "                 tmp2['/test_transport_simple_integral_macroatom_interp/spectrum/_frequency'][:-1], \n",
    "                 tmp2['/test_transport_simple_integral_macroatom_interp/spectrum/wavelength'],\n",
    "                 tmp2['/test_transport_simple_integral_macroatom_interp/spectrum_integrated/luminosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spectrum(tmp1['/test_transport_simple_integral_macroatom/spectrum/_frequency'][:-1], \n",
    "                 tmp1['/test_transport_simple_integral_macroatom/spectrum_integrated/wavelength'],\n",
    "                 tmp1['/test_transport_simple_integral_macroatom/spectrum_integrated/luminosity'],\n",
    "                 tmp2['/test_transport_simple_integral_macroatom/spectrum/_frequency'][:-1], \n",
    "                 tmp2['/test_transport_simple_integral_macroatom/spectrum_integrated/wavelength'],\n",
    "                 tmp2['/test_transport_simple_integral_macroatom/spectrum_integrated/luminosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spectrum(tmp1['/test_transport_simple_integral_downbranch/spectrum/_frequency'][:-1], \n",
    "                 tmp1['/test_transport_simple_integral_downbranch/spectrum/wavelength'],\n",
    "                 tmp1['/test_transport_simple_integral_downbranch/spectrum_integrated/luminosity'],\n",
    "                 tmp2['/test_transport_simple_integral_downbranch/spectrum/_frequency'][:-1], \n",
    "                 tmp2['/test_transport_simple_integral_downbranch/spectrum/wavelength'],\n",
    "                 tmp2['/test_transport_simple_integral_downbranch/spectrum_integrated/luminosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_spectrum(tmp1['/test_transport_simple/spectrum_virtual/_frequency'][:-1], \n",
    "                 tmp1['/test_transport_simple/spectrum_virtual/wavelength'],\n",
    "                 tmp1['/test_transport_simple/spectrum_virtual/luminosity'],\n",
    "                 tmp2['/test_transport_simple/spectrum_virtual/_frequency'][:-1], \n",
    "                 tmp2['/test_transport_simple/spectrum_virtual/wavelength'],\n",
    "                 tmp2['/test_transport_simple/spectrum_virtual/luminosity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T12:30:00.121109Z",
     "start_time": "2018-08-02T12:30:00.088948Z"
    }
   },
   "outputs": [],
   "source": [
    "comparer.teardown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
